{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sequential_NLP_Project_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OudB5by50jlI"
      },
      "source": [
        "## Sequential NLP Project\n",
        "###Digital content and entertainment industry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvtsfVacviSH",
        "outputId": "6ea85a01-371f-424a-8ad3-b81ba112b764"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BsoYtPVwC-s"
      },
      "source": [
        "import os \n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxfwbrbuKbk2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GRU, Embedding,LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0UvTu_1w3Hn",
        "outputId": "9a5da2b7-36af-45c1-f10d-5a9305d5a117"
      },
      "source": [
        "\n",
        "print(\"Train size: \", len(X_train))\n",
        "print(\"Test size:  \", len(X_test))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size:  25000\n",
            "Test size:   25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGal6aKRz3Oj",
        "outputId": "cbceaa65-f073-4b94-ba23-eccf01c1cea4"
      },
      "source": [
        "print(\"X_train Shape \", X_train.shape)\n",
        "print(\"y_train Shape \", y_train.shape)\n",
        "\n",
        "print(\"X_test shape \", X_test.shape)\n",
        "print(\"y_test shape  \", y_test.shape)\n",
        "\n",
        "print(\"Maximum value of a word index \")\n",
        "print(max([max(sequence) for sequence in X_train]))\n",
        "print(\"Maximum length num words of review in train \")\n",
        "print(max([len(sequence) for sequence in X_train]))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Shape  (25000,)\n",
            "y_train Shape  (25000,)\n",
            "X_test shape  (25000,)\n",
            "y_test shape   (25000,)\n",
            "Maximum value of a word index \n",
            "9999\n",
            "Maximum length num words of review in train \n",
            "2494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw3Uk-9Ow3SD"
      },
      "source": [
        ""
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKFyMa28zztL",
        "outputId": "765f5318-2d8a-4657-c550-905a8890743d"
      },
      "source": [
        "X_train[10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 785,\n",
              " 189,\n",
              " 438,\n",
              " 47,\n",
              " 110,\n",
              " 142,\n",
              " 7,\n",
              " 6,\n",
              " 7475,\n",
              " 120,\n",
              " 4,\n",
              " 236,\n",
              " 378,\n",
              " 7,\n",
              " 153,\n",
              " 19,\n",
              " 87,\n",
              " 108,\n",
              " 141,\n",
              " 17,\n",
              " 1004,\n",
              " 5,\n",
              " 2,\n",
              " 883,\n",
              " 2,\n",
              " 23,\n",
              " 8,\n",
              " 4,\n",
              " 136,\n",
              " 2,\n",
              " 2,\n",
              " 4,\n",
              " 7475,\n",
              " 43,\n",
              " 1076,\n",
              " 21,\n",
              " 1407,\n",
              " 419,\n",
              " 5,\n",
              " 5202,\n",
              " 120,\n",
              " 91,\n",
              " 682,\n",
              " 189,\n",
              " 2818,\n",
              " 5,\n",
              " 9,\n",
              " 1348,\n",
              " 31,\n",
              " 7,\n",
              " 4,\n",
              " 118,\n",
              " 785,\n",
              " 189,\n",
              " 108,\n",
              " 126,\n",
              " 93,\n",
              " 2,\n",
              " 16,\n",
              " 540,\n",
              " 324,\n",
              " 23,\n",
              " 6,\n",
              " 364,\n",
              " 352,\n",
              " 21,\n",
              " 14,\n",
              " 9,\n",
              " 93,\n",
              " 56,\n",
              " 18,\n",
              " 11,\n",
              " 230,\n",
              " 53,\n",
              " 771,\n",
              " 74,\n",
              " 31,\n",
              " 34,\n",
              " 4,\n",
              " 2834,\n",
              " 7,\n",
              " 4,\n",
              " 22,\n",
              " 5,\n",
              " 14,\n",
              " 11,\n",
              " 471,\n",
              " 9,\n",
              " 2,\n",
              " 34,\n",
              " 4,\n",
              " 321,\n",
              " 487,\n",
              " 5,\n",
              " 116,\n",
              " 15,\n",
              " 6584,\n",
              " 4,\n",
              " 22,\n",
              " 9,\n",
              " 6,\n",
              " 2286,\n",
              " 4,\n",
              " 114,\n",
              " 2679,\n",
              " 23,\n",
              " 107,\n",
              " 293,\n",
              " 1008,\n",
              " 1172,\n",
              " 5,\n",
              " 328,\n",
              " 1236,\n",
              " 4,\n",
              " 1375,\n",
              " 109,\n",
              " 9,\n",
              " 6,\n",
              " 132,\n",
              " 773,\n",
              " 2,\n",
              " 1412,\n",
              " 8,\n",
              " 1172,\n",
              " 18,\n",
              " 7865,\n",
              " 29,\n",
              " 9,\n",
              " 276,\n",
              " 11,\n",
              " 6,\n",
              " 2768,\n",
              " 19,\n",
              " 289,\n",
              " 409,\n",
              " 4,\n",
              " 5341,\n",
              " 2140,\n",
              " 2,\n",
              " 648,\n",
              " 1430,\n",
              " 2,\n",
              " 8914,\n",
              " 5,\n",
              " 27,\n",
              " 3000,\n",
              " 1432,\n",
              " 7130,\n",
              " 103,\n",
              " 6,\n",
              " 346,\n",
              " 137,\n",
              " 11,\n",
              " 4,\n",
              " 2768,\n",
              " 295,\n",
              " 36,\n",
              " 7740,\n",
              " 725,\n",
              " 6,\n",
              " 3208,\n",
              " 273,\n",
              " 11,\n",
              " 4,\n",
              " 1513,\n",
              " 15,\n",
              " 1367,\n",
              " 35,\n",
              " 154,\n",
              " 2,\n",
              " 103,\n",
              " 2,\n",
              " 173,\n",
              " 7,\n",
              " 12,\n",
              " 36,\n",
              " 515,\n",
              " 3547,\n",
              " 94,\n",
              " 2547,\n",
              " 1722,\n",
              " 5,\n",
              " 3547,\n",
              " 36,\n",
              " 203,\n",
              " 30,\n",
              " 502,\n",
              " 8,\n",
              " 361,\n",
              " 12,\n",
              " 8,\n",
              " 989,\n",
              " 143,\n",
              " 4,\n",
              " 1172,\n",
              " 3404,\n",
              " 10,\n",
              " 10,\n",
              " 328,\n",
              " 1236,\n",
              " 9,\n",
              " 6,\n",
              " 55,\n",
              " 221,\n",
              " 2989,\n",
              " 5,\n",
              " 146,\n",
              " 165,\n",
              " 179,\n",
              " 770,\n",
              " 15,\n",
              " 50,\n",
              " 713,\n",
              " 53,\n",
              " 108,\n",
              " 448,\n",
              " 23,\n",
              " 12,\n",
              " 17,\n",
              " 225,\n",
              " 38,\n",
              " 76,\n",
              " 4397,\n",
              " 18,\n",
              " 183,\n",
              " 8,\n",
              " 81,\n",
              " 19,\n",
              " 12,\n",
              " 45,\n",
              " 1257,\n",
              " 8,\n",
              " 135,\n",
              " 15,\n",
              " 2,\n",
              " 166,\n",
              " 4,\n",
              " 118,\n",
              " 7,\n",
              " 45,\n",
              " 2,\n",
              " 17,\n",
              " 466,\n",
              " 45,\n",
              " 2,\n",
              " 4,\n",
              " 22,\n",
              " 115,\n",
              " 165,\n",
              " 764,\n",
              " 6075,\n",
              " 5,\n",
              " 1030,\n",
              " 8,\n",
              " 2973,\n",
              " 73,\n",
              " 469,\n",
              " 167,\n",
              " 2127,\n",
              " 2,\n",
              " 1568,\n",
              " 6,\n",
              " 87,\n",
              " 841,\n",
              " 18,\n",
              " 4,\n",
              " 22,\n",
              " 4,\n",
              " 192,\n",
              " 15,\n",
              " 91,\n",
              " 7,\n",
              " 12,\n",
              " 304,\n",
              " 273,\n",
              " 1004,\n",
              " 4,\n",
              " 1375,\n",
              " 1172,\n",
              " 2768,\n",
              " 2,\n",
              " 15,\n",
              " 4,\n",
              " 22,\n",
              " 764,\n",
              " 55,\n",
              " 5773,\n",
              " 5,\n",
              " 14,\n",
              " 4233,\n",
              " 7444,\n",
              " 4,\n",
              " 1375,\n",
              " 326,\n",
              " 7,\n",
              " 4,\n",
              " 4760,\n",
              " 1786,\n",
              " 8,\n",
              " 361,\n",
              " 1236,\n",
              " 8,\n",
              " 989,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2768,\n",
              " 45,\n",
              " 55,\n",
              " 776,\n",
              " 8,\n",
              " 79,\n",
              " 496,\n",
              " 98,\n",
              " 45,\n",
              " 400,\n",
              " 301,\n",
              " 15,\n",
              " 4,\n",
              " 1859,\n",
              " 9,\n",
              " 4,\n",
              " 155,\n",
              " 15,\n",
              " 66,\n",
              " 2,\n",
              " 84,\n",
              " 5,\n",
              " 14,\n",
              " 22,\n",
              " 1534,\n",
              " 15,\n",
              " 17,\n",
              " 4,\n",
              " 167,\n",
              " 2,\n",
              " 15,\n",
              " 75,\n",
              " 70,\n",
              " 115,\n",
              " 66,\n",
              " 30,\n",
              " 252,\n",
              " 7,\n",
              " 618,\n",
              " 51,\n",
              " 9,\n",
              " 2161,\n",
              " 4,\n",
              " 3130,\n",
              " 5,\n",
              " 14,\n",
              " 1525,\n",
              " 8,\n",
              " 6584,\n",
              " 15,\n",
              " 2,\n",
              " 165,\n",
              " 127,\n",
              " 1921,\n",
              " 8,\n",
              " 30,\n",
              " 179,\n",
              " 2532,\n",
              " 4,\n",
              " 22,\n",
              " 9,\n",
              " 906,\n",
              " 18,\n",
              " 6,\n",
              " 176,\n",
              " 7,\n",
              " 1007,\n",
              " 1005,\n",
              " 4,\n",
              " 1375,\n",
              " 114,\n",
              " 4,\n",
              " 105,\n",
              " 26,\n",
              " 32,\n",
              " 55,\n",
              " 221,\n",
              " 11,\n",
              " 68,\n",
              " 205,\n",
              " 96,\n",
              " 5,\n",
              " 4,\n",
              " 192,\n",
              " 15,\n",
              " 4,\n",
              " 274,\n",
              " 410,\n",
              " 220,\n",
              " 304,\n",
              " 23,\n",
              " 94,\n",
              " 205,\n",
              " 109,\n",
              " 9,\n",
              " 55,\n",
              " 73,\n",
              " 224,\n",
              " 259,\n",
              " 3786,\n",
              " 15,\n",
              " 4,\n",
              " 22,\n",
              " 528,\n",
              " 1645,\n",
              " 34,\n",
              " 4,\n",
              " 130,\n",
              " 528,\n",
              " 30,\n",
              " 685,\n",
              " 345,\n",
              " 17,\n",
              " 4,\n",
              " 277,\n",
              " 199,\n",
              " 166,\n",
              " 281,\n",
              " 5,\n",
              " 1030,\n",
              " 8,\n",
              " 30,\n",
              " 179,\n",
              " 4442,\n",
              " 444,\n",
              " 2,\n",
              " 9,\n",
              " 6,\n",
              " 371,\n",
              " 87,\n",
              " 189,\n",
              " 22,\n",
              " 5,\n",
              " 31,\n",
              " 7,\n",
              " 4,\n",
              " 118,\n",
              " 7,\n",
              " 4,\n",
              " 2068,\n",
              " 545,\n",
              " 1178,\n",
              " 829]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FoehB5jNd1g",
        "outputId": "4bdbfa0a-54f8-4d3a-b981-c08dfaeca88a"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cof4LSxNxuv"
      },
      "source": [
        "#### Decode the feature value to get original sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clsk-yK8OtzD",
        "outputId": "9838d632-4ebb-49de-8b62-57695e31f591"
      },
      "source": [
        "# See an actual review in words\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "reverse_word_index = dict(\n",
        "[(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "decoded_review = ' '.join(\n",
        "[reverse_word_index.get(i - 3, '?') for i in X_train[10]])\n",
        "\n",
        "print(decoded_review)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "? french horror cinema has seen something of a revival over the last couple of years with great films such as inside and ? romance ? on to the scene ? ? the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made ? was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is ? by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named ? sent to prison for fraud he is put in a cell with three others the quietly insane ? body building ? marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old ? after ? part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that ? makes the best of it's ? as despite it's ? the film never actually feels restrained and manages to flow well throughout director eric ? provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell ? that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really ? people and this film proves that as the director ? that we can never really be sure of exactly what is round the corner and this helps to ensure that ? actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall ? is a truly great horror film and one of the best of the decade highly recommended viewing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRgOD5S2Uuvd"
      },
      "source": [
        "Now use the dictionary to get the original words from the encodings, for a particular sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ504QDORwxj",
        "outputId": "ff822f92-98a5-4258-bf7b-f4cc9d3b3959"
      },
      "source": [
        "for encoding in X_train[10]:\n",
        "  for key, value in word_index.items():\n",
        "    if encoding == value:\n",
        "      print(key, end = \" \")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the clear fact entertaining there life back br is safely show of performance stars br actors film him many should movie reasons to and reading and are in of scenes and and of safely out compared not boss yes to sentiment show its disappointed fact raw to it justice by br of where clear fact many your way and with city nice are is along wrong not as it way she but this anything up haven't been by who of choices br of you to as this i'd it and who of shot you'll to love for updated of you it is sequels of little quest are seen watched front chemistry to simply alive of chris being it is say easy and cry in chemistry but voodoo all it maybe this is wing film job live of objects relief and level names and dunne to be stops serial 1948 watch is men go this of wing american from russo moving is accepted put this of jerry for places so work and watch and lot br that from sometimes wondered make department introduced to wondered from action at turns in low that in gay i'm of chemistry bible i i simply alive it is time done inspector to watching look world named for more tells up many fans are that movie music her get grasp but seems in people film that if explain in why for and find of where br if and movie throughout if and of you best look red startling to recently in successfully much unfortunately going dan and stuck is him sequences but of you of enough for its br that beautiful put reasons of chris chemistry wing and for of you red time trivia to as companion payoff of chris less br of subplots torture in low alive in gay some br of wing if time actual in also side any if name takes for of friendship it of 10 for had and great to as you students for movie of going and for bad well best had at woman br musical when it caused of gripping to as gem in updated for and look end gene in at world aliens of you it meet but is quite br western ideas of chris little of films he an time done this were right too to of enough for of ending become family beautiful are make right being it time much bit especially craig for of you parts bond who of here parts at due given movie of once give find actor to recently in at world dolls loved and it is video him fact you to by br of where br of grown fight culture leads "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDyQGJT0Ve-a",
        "outputId": "5e38ad40-c532-4987-dda7-d328d61d7a8f"
      },
      "source": [
        "y_train[10]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZHFvRh65mWx"
      },
      "source": [
        "X_train = pad_sequences(X_train, maxlen = 500)\n",
        "X_test =  pad_sequences(X_test, maxlen = 500)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvLOdCBw6Gvv",
        "outputId": "bd41fdd8-f80c-4078-dc05-be58543daf5d"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 500), (25000, 500))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np5GxT1caFEq"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Flatten, Dense, TimeDistributed\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = 10000, output_dim = 100, input_length = 500))\n",
        "model.add(LSTM(64,  return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3JMz-RU8eTE",
        "outputId": "aaa16faa-b40a-45bf-e5f1-72e5d336fb93"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 500, 100)          1000000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 500, 64)           42240     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 32000)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               16384512  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,558,337\n",
            "Trainable params: 17,558,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw4RJ0CQbwFY"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmkolKP4b-U6"
      },
      "source": [
        "### Fit the model (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRg3KFXLcAkk",
        "outputId": "612decda-fa2d-47ec-fdb1-02fd1b06eac9"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 45s 110ms/step - loss: 0.3476 - accuracy: 0.8414 - val_loss: 0.3034 - val_accuracy: 0.8743\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.1665 - accuracy: 0.9363 - val_loss: 0.3800 - val_accuracy: 0.8662\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.0569 - accuracy: 0.9804 - val_loss: 0.4805 - val_accuracy: 0.8658\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.6370 - val_accuracy: 0.8669\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.0204 - accuracy: 0.9923 - val_loss: 0.7085 - val_accuracy: 0.8636\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.8638 - val_accuracy: 0.8487\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 42s 106ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.7710 - val_accuracy: 0.8621\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.7677 - val_accuracy: 0.8605\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 41s 106ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.9736 - val_accuracy: 0.8730\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 41s 105ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.8989 - val_accuracy: 0.8677\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f063ab55390>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUqY-bD8RaDR",
        "outputId": "138bef8e-b3f5-470a-9c65-7a75b0fb7b39"
      },
      "source": [
        "acc_score = model.evaluate(X_test, y_test)\n",
        "print(\" Accuracy %:{}\".format( acc_score[1]*100))\n",
        "print(\"Loss: {}\".format(acc_score[0]))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 28s 35ms/step - loss: 0.8989 - accuracy: 0.8677\n",
            " Accuracy %:86.7680013179779\n",
            "Loss: 0.8989366292953491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl4idfWR_A8E",
        "outputId": "85c5c3f3-8a49-4c2d-d34d-c90b11ddb2cb"
      },
      "source": [
        "#Prediction\n",
        "y_pred = model.predict(X_test[0].reshape((1, 500)))\n",
        "y_pred"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.90296924]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0Xkd0_W_zsZ",
        "outputId": "f112eb6f-3875-48e4-cc2c-65803dc631fe"
      },
      "source": [
        "# CNN for the IMDB \n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "...\n",
        "# create the model\n",
        "model_CNN = Sequential()\n",
        "model_CNN.add(Embedding(64, 32, input_length=500))\n",
        "model_CNN.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model_CNN.add(MaxPooling1D(pool_size=2))\n",
        "model_CNN.add(Flatten())\n",
        "model_CNN.add(Dense(250, activation='relu'))\n",
        "model_CNN.add(Dense(1, activation='sigmoid'))\n",
        "model_CNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_CNN.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 500, 32)           2048      \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 500, 32)           3104      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 250, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 8000)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 250)               2000250   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 251       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,005,653\n",
            "Trainable params: 2,005,653\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXzPcQ1Q_z6M",
        "outputId": "9f16d6ea-b2c0-40a0-a948-e69f81899f7c"
      },
      "source": [
        "model_CNN.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 6s 13ms/step - loss: 0.6403 - accuracy: 0.6181 - val_loss: 0.6120 - val_accuracy: 0.6633\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5841 - accuracy: 0.6913 - val_loss: 0.6003 - val_accuracy: 0.6740\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.5435 - accuracy: 0.7224 - val_loss: 0.5993 - val_accuracy: 0.6766\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.4952 - accuracy: 0.7552 - val_loss: 0.6266 - val_accuracy: 0.6760\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.4272 - accuracy: 0.7978 - val_loss: 0.6673 - val_accuracy: 0.6629\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.3392 - accuracy: 0.8508 - val_loss: 0.7788 - val_accuracy: 0.6576\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.2242 - accuracy: 0.9147 - val_loss: 0.9310 - val_accuracy: 0.6481\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.1105 - accuracy: 0.9703 - val_loss: 1.2277 - val_accuracy: 0.6434\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.0398 - accuracy: 0.9943 - val_loss: 1.6177 - val_accuracy: 0.6429\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.0117 - accuracy: 0.9998 - val_loss: 1.8371 - val_accuracy: 0.6418\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f06362e8590>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdbXlqq17W6a",
        "outputId": "ff595254-b13d-46b3-b267-1bff3e86423f"
      },
      "source": [
        "acc_score_CNN = model_CNN.evaluate(X_test, y_test)\n",
        "print(\" Accuracy %:{}\".format( acc_score_CNN[1]*100))\n",
        "print(\"Loss: {}\".format(acc_score_CNN[0]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 4ms/step - loss: 1.8371 - accuracy: 0.6418\n",
            " Accuracy %:64.18399810791016\n",
            "Loss: 1.837062954902649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_7CPwLmAysU",
        "outputId": "21b035e8-ac2e-414d-8591-28f4706d2f73"
      },
      "source": [
        "model_CNN.predict(X_test[0].reshape((1, 500)))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04925568]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W76Wd2mFHmmu"
      },
      "source": [
        "NLP with LSTM is better model as compared to CNN.\n"
      ]
    }
  ]
}