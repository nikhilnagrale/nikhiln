{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "StatisticalNLP_Project_Part_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8DpYtDREs1K"
      },
      "source": [
        "To create a classifier that predicts multiple features of the author of a given text, designed as a Multi label classification problem\n",
        "The need is to build a NLP classifier which can use input text parameters to determine the label/s of of the blog."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23QncHQR34yU"
      },
      "source": [
        "Dataset is taken from \n",
        "https://www.kaggle.com/rtatman/blog-authorship-corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3H0K9exCoDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd74627c-8d3b-4b1a-cbea-c19f0a81fef8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLaRcWEVs24d"
      },
      "source": [
        "import os \n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI1WCMoH34yf"
      },
      "source": [
        "#### Read the csv using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnHeJhCb34yh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('blogtext.csv')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3nNUnfStRCo"
      },
      "source": [
        "Data set info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSdOhe9I34yr"
      },
      "source": [
        "#### Get the names of the columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8o5o6gatV1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "dec0f70d-4103-4b94-e71c-3a6507e70246"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>14,May,2004</td>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>13,May,2004</td>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>11,June,2004</td>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                               text\n",
              "0  2059027  ...             Info has been found (+/- 100 pages,...\n",
              "1  2059027  ...             These are the team members:   Drewe...\n",
              "2  2059027  ...             In het kader van kernfusie op aarde...\n",
              "3  2059027  ...                   testing!!!  testing!!!          \n",
              "4  3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iyXOyz7x_Pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec8411f-2577-4501-a3a3-dbf412a1680d"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(681284, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65-iG85P34ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac5af54-ab90-44f4-99a3-629361046d73"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQMujlOu34y4"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YrEdXTutfa0"
      },
      "source": [
        "Check for NULL values in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wf-Wt1VI34y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbc575d-6102-46dd-e711-efaa50527234"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        0\n",
              "gender    0\n",
              "age       0\n",
              "topic     0\n",
              "sign      0\n",
              "date      0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8JgNKCq9WIo"
      },
      "source": [
        "Working on full df leads to crash in google collab. while fitting the model\n",
        "So limiting it to 10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXT2ttnF34y-"
      },
      "source": [
        "df = df.head(10000)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwAKaFHX34zD"
      },
      "source": [
        "####Perform data pre-processing on the data:\n",
        "\n",
        "Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK99q02X34zE"
      },
      "source": [
        "# Select only alphabets\n",
        "import re\n",
        "df.text = df.text.apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))\n",
        "\n",
        "# Convert text to lowercase\n",
        "df.text = df.text.apply(lambda x: x.lower())\n",
        "\n",
        "# Strip unwanted spaces\n",
        "df.text = df.text.apply(lambda x: x.strip())\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D37iDZuHyIRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3924b9-72e7-4652-bdf5-22d38ed7c893"
      },
      "source": [
        "# Remove stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "df.text = df.text.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRQBh8YqyMNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab13b07f-dab2-4892-d900-ae204ad4c85d"
      },
      "source": [
        "print(stopwords)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'in', \"you're\", 'themselves', \"doesn't\", 'out', 'over', 'himself', 'didn', 'just', 'd', \"haven't\", 'mightn', 'haven', 'about', \"you'll\", 'what', 'of', 'which', 'off', 'ain', 'because', 'any', 'has', 'all', 'below', \"should've\", 'm', 'we', 'your', 'yours', 'further', 'so', 'my', 'both', 'needn', 'here', 'between', 'during', \"needn't\", 'then', \"that'll\", 'those', 'above', 'did', 'whom', 'if', 'theirs', 'than', 'again', 'him', \"shan't\", 'being', 'y', 'shouldn', 'at', \"couldn't\", 'doesn', 'them', 'had', 'she', 'up', 'does', 'hasn', 'when', 'other', \"she's\", 'now', 'do', \"hadn't\", 'on', 'as', 'should', 'wouldn', 'it', 'having', 'into', 'hadn', 'why', 'was', 'only', 'our', 'too', \"mightn't\", 'before', 'its', 't', 'few', \"won't\", 'some', \"didn't\", 'are', 'o', 'each', 'am', \"isn't\", 'mustn', 'there', 'his', 'such', 'don', 'itself', 'll', 'me', 'ma', 'down', \"aren't\", 'be', 'were', 'weren', 'a', \"weren't\", 'no', 'will', 'most', \"you'd\", 'isn', 'hers', \"it's\", 'where', 'they', 'her', 'shan', 'been', 'for', 'this', 'or', \"hasn't\", 'doing', 'is', 'who', \"wasn't\", 'aren', 'once', 'couldn', 'can', \"shouldn't\", 'to', 'these', 'how', 'against', 's', 'under', 'until', 'more', 'own', 'an', 'while', 'you', 'i', 'by', 'not', 'herself', 'won', 'yourselves', 'the', 'same', \"don't\", 'that', 'and', 'with', 'through', 've', 'wasn', 'their', 'very', 'ourselves', 'he', 'have', 'after', \"you've\", \"mustn't\", 'ours', \"wouldn't\", 'yourself', 're', 'but', 'nor', 'from', 'myself'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdWuim0934zI"
      },
      "source": [
        "check the value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFAbzRCh34zJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "cf89a35c-7d07-44f6-c130-052494f2b2db"
      },
      "source": [
        "df.text[10]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ah korean language looks difficult first figure read hanguel korea surprisingly easy learn alphabet characters seems easy vocabulary starts oh backwards us sentence structure yikes luckily many options us slow witted foreigners take language course could list urllink joongang article says lot resources urllink well guy motivation jeon ji hyun latest something actually star movies cfs hear means commercial feature positive saw latest movie sunday night hard describe name english version windstruck korean version yeochinso short ne yeojachingu rul sogayhamnida like introduce girlfriend surprisingly titles make sense like website korean english looks quite good actually urllink movie shown theatres subtitles special times info urllink list many theatres seoul click urllink urllink great reason learn korean already married went foreigners well local korean national course korean take picture put urllink movie hof bar update bud mine passed urllink link giordano ad apparently aired korea nothing xxx sensibilities sort'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn6zXvBP34zM"
      },
      "source": [
        "#### Target/label merger and transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWIvmq7b34zN"
      },
      "source": [
        "Merging  of all  label columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcgNwo6X34zO"
      },
      "source": [
        "df['labels'] = df.apply(lambda row: [row['gender'], str(row['age']), row['topic'], row['sign']], axis=1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBHZfMM1ukSc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "0a578e8e-d0ae-4eee-d03d-190ee117d371"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>14,May,2004</td>\n",
              "      <td>info found pages mb pdf files wait untill team...</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>13,May,2004</td>\n",
              "      <td>team members drewes van der laag urllink mail ...</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                    labels\n",
              "0  2059027  ...  [male, 15, Student, Leo]\n",
              "1  2059027  ...  [male, 15, Student, Leo]\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZZnsemH34zR"
      },
      "source": [
        "#### Using text and label info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eU2kfOL34zS"
      },
      "source": [
        "df = df[['text','labels']]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8kpqVJ0u2Ss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "b87b8560-2b08-4795-bd97-4d123b73c799"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>info found pages mb pdf files wait untill team...</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>team members drewes van der laag urllink mail ...</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>testing testing</td>\n",
              "      <td>[male, 15, Student, Leo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
              "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                   labels\n",
              "0  info found pages mb pdf files wait untill team...                 [male, 15, Student, Leo]\n",
              "1  team members drewes van der laag urllink mail ...                 [male, 15, Student, Leo]\n",
              "2  het kader van kernfusie op aarde maak je eigen...                 [male, 15, Student, Leo]\n",
              "3                                    testing testing                 [male, 15, Student, Leo]\n",
              "4  thanks yahoo toolbar capture urls popups means...  [male, 33, InvestmentBanking, Aquarius]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35x5UC4V34zZ"
      },
      "source": [
        "#### Train and test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwhJKUZx34za"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text.values, df.labels.values, test_size=0.20, random_state=1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNgeN7bY34zd"
      },
      "source": [
        "#### Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGhmv2F034ze"
      },
      "source": [
        "#### Create BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxCEuvT534zf"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G04WpfQh34zj"
      },
      "source": [
        "#### Checking feature names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wneGQ7cl34zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067743f1-5e8d-46a6-9d69-38f91abb9da5"
      },
      "source": [
        "vectorizer.get_feature_names()[:10]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aa',\n",
              " 'aa amazing',\n",
              " 'aa anger',\n",
              " 'aa compared',\n",
              " 'aa keeps',\n",
              " 'aa sd',\n",
              " 'aaa',\n",
              " 'aaa come',\n",
              " 'aaa rated',\n",
              " 'aaa someone']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT_pkHoO34zu"
      },
      "source": [
        "#### get label counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n71bVKdo34zv"
      },
      "source": [
        "label_counts = dict()\n",
        "\n",
        "for labels in df.labels.values:\n",
        "    for label in labels:\n",
        "        if label in label_counts:\n",
        "            label_counts[label] += 1\n",
        "        else:\n",
        "            label_counts[label] = 1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zoWzSvq34zz"
      },
      "source": [
        "#### Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bXDgiwD34z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0208be28-489e-4ce2-fdd9-57eec5b64703"
      },
      "source": [
        "label_counts"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'13': 42,\n",
              " '14': 212,\n",
              " '15': 602,\n",
              " '16': 440,\n",
              " '17': 1185,\n",
              " '23': 253,\n",
              " '24': 655,\n",
              " '25': 386,\n",
              " '26': 234,\n",
              " '27': 1054,\n",
              " '33': 136,\n",
              " '34': 553,\n",
              " '35': 2315,\n",
              " '36': 1708,\n",
              " '37': 33,\n",
              " '38': 46,\n",
              " '39': 79,\n",
              " '40': 1,\n",
              " '41': 20,\n",
              " '42': 14,\n",
              " '43': 6,\n",
              " '44': 3,\n",
              " '45': 16,\n",
              " '46': 7,\n",
              " 'Accounting': 4,\n",
              " 'Aquarius': 571,\n",
              " 'Aries': 4198,\n",
              " 'Arts': 45,\n",
              " 'Automotive': 14,\n",
              " 'Banking': 16,\n",
              " 'BusinessServices': 91,\n",
              " 'Cancer': 504,\n",
              " 'Capricorn': 215,\n",
              " 'Communications-Media': 99,\n",
              " 'Consulting': 21,\n",
              " 'Education': 270,\n",
              " 'Engineering': 127,\n",
              " 'Fashion': 1622,\n",
              " 'Gemini': 150,\n",
              " 'HumanResources': 2,\n",
              " 'Internet': 118,\n",
              " 'InvestmentBanking': 70,\n",
              " 'Law': 11,\n",
              " 'LawEnforcement-Security': 10,\n",
              " 'Leo': 301,\n",
              " 'Libra': 491,\n",
              " 'Marketing': 156,\n",
              " 'Museums-Libraries': 17,\n",
              " 'Non-Profit': 71,\n",
              " 'Pisces': 454,\n",
              " 'Publishing': 4,\n",
              " 'Religion': 9,\n",
              " 'Sagittarius': 1097,\n",
              " 'Science': 63,\n",
              " 'Scorpio': 971,\n",
              " 'Sports-Recreation': 80,\n",
              " 'Student': 1137,\n",
              " 'Taurus': 812,\n",
              " 'Technology': 2654,\n",
              " 'Telecommunications': 2,\n",
              " 'Virgo': 236,\n",
              " 'female': 4084,\n",
              " 'indUnk': 3287,\n",
              " 'male': 5916}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAa0bCY234z3"
      },
      "source": [
        "#### Multi label binarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_6gL7JX34z5"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "binarizer = MultiLabelBinarizer(classes=sorted(label_counts.keys()))\n",
        "y_train = binarizer.fit_transform(y_train)\n",
        "y_test = binarizer.transform(y_test)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBWM7_CT34z9"
      },
      "source": [
        "#### 3. Design, train, tune and test the best text classifier.\n",
        "\n",
        "Use a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on every label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTDalv2-34z-"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model = OneVsRestClassifier(model)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4njir1Z340B"
      },
      "source": [
        "### Fit the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6VCWVevBHJy",
        "outputId": "5e2fe517-2997-463d-e857-c936ac6716c3"
      },
      "source": [
        "model.fit(X_train_bow, y_train)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='lbfgs', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rgEfe6l340G"
      },
      "source": [
        "#### Predictions\n",
        "- calculating predicted labels and scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBcgoW8O340H"
      },
      "source": [
        "predict_labels = model.predict(X_test_bow)\n",
        "predict_scores = model.decision_function(X_test_bow)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-pvYIj9340K"
      },
      "source": [
        "#### Calculating inverse transform for predicted labels and test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLXR4BIE340L"
      },
      "source": [
        "pred_inversed = binarizer.inverse_transform(predict_labels)\n",
        "y_test_inversed = binarizer.inverse_transform(y_test)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Vmhsrs340P"
      },
      "source": [
        "### Print the true vs predicted labels for dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iax6yXDj340R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec8e05d-713a-45aa-f66e-1daab0f3276d"
      },
      "source": [
        "for i in range(10):\n",
        "    print('Title:\\t{}\\nActual labels:\\t{}\\nPredict labels:\\t{}\\n\\n'.format(\n",
        "        X_test[i],\n",
        "        ','.join(y_test_inversed[i]),\n",
        "        ','.join(pred_inversed[i])\n",
        "    ))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title:\tsucky mcsuckmeister nbsp freaking hate geoff nbsp gave decision love want get respect nbsp get hear loves every single day nbsp love end phone msn convos nbsp nbsp otherwise die nbsp never able fall love anyone else cause still hung geoff hate hate hate nbsp hate\n",
            "Actual labels:\t16,Capricorn,female,indUnk\n",
            "Predict labels:\tfemale\n",
            "\n",
            "\n",
            "Title:\tstaunch religious conservative republicans much problem annoying pussy liberals republicans longer party devoted freedom mainly religious party governs us based religious philosiphies even besides religion longer believe gun rights made patriot act claim small government quite opposite back religion annoying radical christian government tell country sex bad forth john ashcroft like epitome religious authoritarian conservative ashcroft spearheaded huge anti porn campaign supported way tighter fcc regulations things majorly piss whole christian crusade abortion sex porn drugs name belong national policy enough annoying fundamentalists imposing hey church organizations lobby groups preach people whatever whe hell want keep outta government\n",
            "Actual labels:\t14,Pisces,Student,male\n",
            "Predict labels:\t35,Aries,Technology,male\n",
            "\n",
            "\n",
            "Title:\ttime passes wait grows longer end seems less likely come worth\n",
            "Actual labels:\t17,Scorpio,female,indUnk\n",
            "Predict labels:\t35,Aries,Technology,male\n",
            "\n",
            "\n",
            "Title:\tsea urllink angel demon brought urllink quizilla\n",
            "Actual labels:\t36,Pisces,female,indUnk\n",
            "Predict labels:\t36,female,indUnk\n",
            "\n",
            "\n",
            "Title:\tpicture probably going really big delete later bad computer broken use picasa fix arg bobby outside hotel dad says giving evil eye really looking\n",
            "Actual labels:\t17,Scorpio,female,indUnk\n",
            "Predict labels:\tfemale\n",
            "\n",
            "\n",
            "Title:\tharlo sat choice stay home study exams days national day coming going cousin sooo fun haha nvm think enough start gtg study p hasnt online yet dunno maybe training\n",
            "Actual labels:\t14,Cancer,Student,male\n",
            "Predict labels:\tmale\n",
            "\n",
            "\n",
            "Title:\tthanks mir worked julie came back home another week couch phew\n",
            "Actual labels:\t35,Aries,Technology,male\n",
            "Predict labels:\t35,Aries,Technology,male\n",
            "\n",
            "\n",
            "Title:\thrmm wonder fight scene imagining\n",
            "Actual labels:\t35,Aries,Technology,male\n",
            "Predict labels:\t35,Aries,Technology,male\n",
            "\n",
            "\n",
            "Title:\tdrool bit overbearing times deal love love love love crazy love\n",
            "Actual labels:\t35,Aries,Technology,male\n",
            "Predict labels:\t35,Aries,Technology,male\n",
            "\n",
            "\n",
            "Title:\tdisclaimer normally writings actually include pronouns today sigh approaching fiftieth post say shall big black tie bash invite big names nanaimo theatre unless want pay nothing blog surfing dog walking morning sleeping bed enjoyable beyond comparison woke drank coffee fought sister stormed house rage towing ahrodie along behind formulated plans move must leave must leave cleaned sherayna children breakfast dishes probably end cleaning puppies poop thanks bunch big sister blog surfing came across sarah bobarah blog say know well serious actually shy even post tag blog fear would think creepy ahh insecurity speaks blogging bringing geek everybody heartily agree logging pinto fun bloglines gorky neurotic merely rather trying day oh trying kid dork anyway hereby demand everybody actually reads entire post must leave comment know babble trip already read post besides also tells compliment reading stamina get entire thing without dying boredom deserve kudos bought cool shirt frogs wedding pictures turned crappy crappy times million pics david scanner anymore life sucks today wore tan shorts new orange froggie tee mutilated old pink sandals cause unpacked blue white ones yet matching set underwear course hundred sex bracelets shall begin distributing soon ate coffee angry appetite ahrodie walking involved taking maffeo sutton continuing interdog relation training water familiarization training terms mean nothing want able swim attack dogs like idea living place away stupid family dislike stupid family brag moment throwing ball water ahrodie warily wade retrieve progress well seems rather well behaved around smaller female dogs larger male dogs odd cringe moment walking sidewalk blinking tears rage eyes hate crying cause mad granola moment lying grass shade maffeo sutton ahrodie unfortunately closeness ocean comforting usually disappointment plan hang kevin eventually finish current babysitting rob kaelyn steven might croup sherayna taking baby doctor\n",
            "Actual labels:\t16,Capricorn,female,indUnk\n",
            "Predict labels:\tfemale\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwWuEQdq340U"
      },
      "source": [
        "#### 4. Display and explain detail the classification report\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGw0pAEzxw_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "def display_metrics_micro(Ytest, Ypred):\n",
        "    print('Accuracy score: ', accuracy_score(Ytest, Ypred))\n",
        "    print('F1 score: Micro', f1_score(Ytest, Ypred, average='micro'))\n",
        "    print('Average precision score: Micro', average_precision_score(Ytest, Ypred, average='micro'))\n",
        "    print('Average recall score: Micro', recall_score(Ytest, Ypred, average='micro'))\n",
        "    \n",
        "    \n",
        "def display_metrics_macro(Ytest, Ypred):\n",
        "    print('Accuracy score: ', accuracy_score(Ytest, Ypred))\n",
        "    print('F1 score: Macro', f1_score(Ytest, Ypred, average='macro'))\n",
        "    print('Average recall score: Macro', recall_score(Ytest, Ypred, average='macro'))\n",
        "    \n",
        "def display_metrics_weighted(Ytest, Ypred):\n",
        "    print('Accuracy score: ', accuracy_score(Ytest, Ypred))\n",
        "    print('F1 score: weighted', f1_score(Ytest, Ypred, average='weighted'))\n",
        "    print('Average precision score: weighted', average_precision_score(Ytest, Ypred, average='weighted'))\n",
        "    print('Average recall score: weighted', recall_score(Ytest, Ypred, average='weighted'))\n",
        "    "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKSUMuN4z7ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965f4ffe-2a98-410a-ed9d-164a8d701c83"
      },
      "source": [
        "display_metrics_micro(y_test,predict_labels)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.315\n",
            "F1 score: Micro 0.6423666138404648\n",
            "Average precision score: Micro 0.46044253475528474\n",
            "Average recall score: Micro 0.532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3im2t8U0z7wK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88bc973-c3b2-470b-d972-714cfa96864a"
      },
      "source": [
        "display_metrics_macro(y_test,predict_labels)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.315\n",
            "F1 score: Macro 0.21713773753890891\n",
            "Average recall score: Macro 0.1660267706887283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu5ilRrUz72m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40f637f-6acc-4579-ff46-e4aae373983e"
      },
      "source": [
        "display_metrics_weighted(y_test,predict_labels)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.315\n",
            "F1 score: weighted 0.5944270384254596\n",
            "Average precision score: weighted 0.514864020887684\n",
            "Average recall score: weighted 0.532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZxf6jap1KDF"
      },
      "source": [
        "#### Using a linear classifier  and  wrapping it up in OneVsRestClassifier to train it on every label\n",
        "LR, SVM, NaiveBayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejEYRq2k340d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "def build_model_train(X_train, y_train, X_valid=None, y_valid=None, C=1.0, model='lr'):\n",
        "    if model=='lr':\n",
        "        model = LogisticRegression(C=C, penalty='l1', dual=False, solver='liblinear')\n",
        "        model = OneVsRestClassifier(model)\n",
        "        model.fit(X_train, y_train)\n",
        "    \n",
        "    elif model=='svm':\n",
        "        model = LinearSVC(C=C, penalty='l1', dual=False, loss='squared_hinge')\n",
        "        model = OneVsRestClassifier(model)\n",
        "        model.fit(X_train, y_train)\n",
        "    \n",
        "    elif model=='nbayes':\n",
        "        model = MultinomialNB(alpha=1.0)\n",
        "        model = OneVsRestClassifier(model)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWAmQt3P1Fdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32784855-288f-4e7d-94e3-57f702ce63ae"
      },
      "source": [
        "models = ['lr','svm','nbayes']\n",
        "for model in models:\n",
        "    print({model})\n",
        "    model = build_model_train(X_train_bow,y_train,model=model)\n",
        "    model.fit(X_train_bow,y_train)\n",
        "    Ypred=model.predict(X_test_bow)\n",
        "    print(\"\\n\")\n",
        "    print(f\"**displaying  metrics for the mode {model}\\n\")\n",
        "    display_metrics_micro(y_test,Ypred)\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")\n",
        "    display_metrics_macro(y_test,Ypred)\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")\n",
        "    display_metrics_weighted(y_test,Ypred)\n",
        "    print(\"\\n\")\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr'}\n",
            "\n",
            "\n",
            "**displaying  metrics for the mode OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
            "                                                 dual=False, fit_intercept=True,\n",
            "                                                 intercept_scaling=1,\n",
            "                                                 l1_ratio=None, max_iter=100,\n",
            "                                                 multi_class='auto',\n",
            "                                                 n_jobs=None, penalty='l1',\n",
            "                                                 random_state=None,\n",
            "                                                 solver='liblinear', tol=0.0001,\n",
            "                                                 verbose=0, warm_start=False),\n",
            "                    n_jobs=None)\n",
            "\n",
            "Accuracy score:  0.343\n",
            "F1 score: Micro 0.6737785363772135\n",
            "Average precision score: Micro 0.48826996756929547\n",
            "Average recall score: Micro 0.592125\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score:  0.343\n",
            "F1 score: Macro 0.34031652431543735\n",
            "Average recall score: Macro 0.2696847896890724\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score:  0.343\n",
            "F1 score: weighted 0.6510893500046282\n",
            "Average precision score: weighted 0.5428846250813815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average recall score: weighted 0.592125\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "{'svm'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "**displaying  metrics for the mode OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
            "                                        fit_intercept=True, intercept_scaling=1,\n",
            "                                        loss='squared_hinge', max_iter=1000,\n",
            "                                        multi_class='ovr', penalty='l1',\n",
            "                                        random_state=None, tol=0.0001,\n",
            "                                        verbose=0),\n",
            "                    n_jobs=None)\n",
            "\n",
            "Accuracy score:  0.3275\n",
            "F1 score: Micro 0.6675879223381469\n",
            "Average precision score: Micro 0.475448392601962\n",
            "Average recall score: Micro 0.603875\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score:  0.3275\n",
            "F1 score: Macro 0.376787507460514\n",
            "Average recall score: Macro 0.3069679492077122\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score:  0.3275\n",
            "F1 score: weighted 0.6502124163652602\n",
            "Average precision score: weighted 0.5330947516251924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average recall score: weighted 0.603875\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "{'nbayes'}\n",
            "\n",
            "\n",
            "**displaying  metrics for the mode OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
            "                                            fit_prior=True),\n",
            "                    n_jobs=None)\n",
            "\n",
            "Accuracy score:  0.0475\n",
            "F1 score: Micro 0.4149056603773584\n",
            "Average precision score: Micro 0.2778011298076923\n",
            "Average recall score: Micro 0.274875\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score:  0.0475\n",
            "F1 score: Macro 0.0632447435320839\n",
            "Average recall score: Macro 0.046842438349092116\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Accuracy score:  0.0475\n",
            "F1 score: weighted 0.3243996975912275\n",
            "Average precision score: weighted 0.37695397733766733\n",
            "Average recall score: weighted 0.274875\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHlgjpFa1Fl3"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxFWMZzy2Lo8"
      },
      "source": [
        "Multilabel classification problem is solved that predicts multiple features of the author of a given text\n",
        "The data is loaded and required basic EDA and data inspection has been done\n",
        "The text has been pre processed like cleansing it(removing the unnecessary chars, removing the spaces, converting the case to lower) and also removing the stop words, vectorizing the features\n",
        "Preparing the data and splitting them to train and test\n",
        "using multilable binarizers, also various classifier models are trained and the predictions are made and also the accuracy, f1 score, Avg precision and recall scores are calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJQoeH2e1Fo-"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gmsLsu53cGC"
      },
      "source": [
        "LR classifier  wrapping it up with OneVsRestClassifier to train it on every label gives better result"
      ]
    }
  ]
}